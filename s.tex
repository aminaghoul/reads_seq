\documentclass[12pt,a4paper]{article} % Format de page
\usepackage[utf8x]{inputenc} % Pour les caractères accentués
\usepackage[T1]{fontenc} % Encodage de caractères
\usepackage{aeguill} % moins flou que la police vectorielle Latin Modern
\usepackage[frenchb]{babel} % Règles typographiques françaises
\usepackage{graphicx} % Insérer des images
\usepackage{hyperref} % Créer des liens et des signets
\hypersetup{
colorlinks=true, %colorise les liens
breaklinks=true, %permet le retour à la ligne dans les liens trop longs
urlcolor= blue, %couleur des hyperliens
linkcolor= black, %couleur des liens internes
citecolor=black, %couleur des références
pdftitle={Rapport de stage}, %informations apparaissant dans
pdfauthor={Anonyme}, %les informations du document
pdfsubject={Simulation} %sous Acrobat.
}
\addtolength{\textwidth}{2cm} % Marges moins larges
\addtolength{\oddsidemargin}{-1cm} % Recentrage
% En-têtes du document
\title{Rapport de stage}
\author{Anonyme}
\date{14 avril 2009}
% Début du document
\begin{document}
% Titre
\pagenumbering{roman}
\maketitle
% Table des matières
\newpage
\section*{Remerciements}

Avant tout développement sur cette expérience professionnelle, il apparaît opportun de commencer ce rapport de stage par des remerciements, à ceux qui m’ont beaucoup appris au cours de ce stage, et même à ceux qui ont eu la gentillesse de faire de ce stage un moment très profitable.

Aussi, je remercie Monsieur Jean-François Gibrat, mon maître de stage qui m’a formé et accompagné tout au long de cette expérience professionnelle avec beaucoup de patience et de pédagogie. Enfin, je remercie l’ensemble des employés de l'INRA pour les conseils qu’ils ont pu me prodiguer au cours de ce stage.
\newpage
\tableofcontents
\newpage
\section{Introduction} 
Le  sujet du stage concerne l'étude de la distribution des longueurs des données (lectures) produites par les technologies de séquençage de 3ème génération.
Dans un premier temps, on vérifiera l'idée que les distributions ainsi obtenues sont des distributions bêta (cas classique de la distribution
des longueurs des morceaux d'un bâton qui a été découpé en N segments
aléatoirement). Dans le cas du séquençage, N est également une
variable aléatoire avec une distribution qui reste à déterminer.
L'objectif de ce stage est de trouver une expression analytique de cette distribution.
\newpage
\section{Contexte du stage} 


Mon stage a été réalisé à l'INRA (Institut national de la recherche agronomique) dans l'unité de recherche "Mathématiques et Informatique Appliquées du Génome à l'Environnement" (MaIAGE), dans l'équipe StatInfOmics (Statistique et Bioinformatique des données Omiques).

Cet institut est un organisme français de recherche en agronomie ayant le statut d’Établissement public à caractère scientifique et technologique, et sous la double tutelle du ministère chargé de la Recherche et du ministère chargé de l’Agriculture. Il est le premier institut de recherche agronomique en Europe et deuxième dans le monde en nombre de publications en sciences agricoles et en sciences de la plante et de l'animal.

L'unité de recherche MaIAGE regroupe des mathématiciens, des informaticiens, des bioinformaticiens et des biologistes autour de questions de biologie et agro-écologie, allant de l'échelle moléculaire à l'échelle du paysage en passant par l'étude de l'individu, de populations ou d'écosystèmes.
L'unité développe des méthodes mathématiques et informatiques originales de portée générique ou motivées par des problèmes biologiques précis. Elle s'implique aussi dans la mise à disposition de bases de données et de logiciels permettant aux biologistes d'utiliser les outils dans de bonnes conditions ou d'exploiter automatiquement la littérature scientifique.

L'inférence statistique et la modélisation dynamique sont des compétences fortes de l'unité, auxquelles s'ajoutent la bioinformatique, l'automatique et l'algorithmique. Les activités de recherche et d'ingénierie s'appuient également sur une forte implication dans les disciplines destinatrices : écologie, environnement, biologie moléculaire et biologie des systèmes.
\newpage
\section{Objectifs de l'équipe} \subsection{Test}
J'ai effectué mon stage dans l'équipe StatInfOmics: Statistique et Bioinformatique des données Omiques.
Cette équipe vise à développer et mettre en oeuvre des méthodes statistiques et bioinformatiques dédiées à l’analyse de données “omiques”. D’un point de vue biologique, les questions abordées concernent principalement l’annotation structurale et fonctionnelle des génomes, les régulations géniques, la dynamique évolutive des génomes, et la caractérisation d’écosystèmes microbiens en terme de diversité et de fonctions présentes ; une cible commune étant la relation entre génotype et phénotype. Une part de plus en plus importante de notre activité est relative à l’intégration de données “omiques” hétérogènes pour en extraire de l’information pertinente et aussi prédire des processus biologiques. D’un point de vue méthodologique, nos travaux sont essentiellement d’ordre statistique : estimation de distributions, inférence de modèles à variables latentes, prédiction de relations entre jeux de variables, segmentation, visualisation et classification, avec une attention particulière au cadre de la grande dimension qui caractérise la majorité des jeux de données “omiques” étudiés. Ces recherches s’appuient souvent sur une ingénierie bioinformatique très forte.
\newpage
\section{Missions effectuées} \subsection{Test}
Contrairement aux précédentes générations qui fournissaient des lectures
de longueur constante et petite (au plus 400 bp), les technologies de 3e
génération produisent une distribution de longueurs avec une médiane à
environ 12 kbp et une queue de distribution qui va jusqu'à 60 kbp pour les
lectures les plus longues.
- Vérifier distribution bêta
- comprendre méthodes séquençage Minion pacbio
- déterminer loi de N, loi séquenceur
- loi composée
- code python simulation et théorique
- optmisation paramètres max de vraisemblance
- choisir loi

\section{Activités et productions} 
On sait que cette distribution de tailles suit une loi de bêta de paramètres 1 et n.
On peut le montrer théoriquement. \\
On s'intéresse au positionnement de lecture $S_{i}$ sur un génome de taille G. $S_{i}$ : position de départ de la $i_{ème}$ lecture sur le génome.\\
Les lectures sont générées aléatoirement et uniformément le long du génome.
Soit $D_{i}$= $S_{i+1}$-$S_{i}$ la distance entre 2 positions de départ consécutives.
On s'intéresse aux statistiques d'ordre.\\
Soit X une variable aléatoire continue et $X_{1}$, $X_{2}$, ... $X_{n}$ des variables aléatoires indépendantes et identiquement distribuées selon la distribution de X.
On définit $X_{1}$ comme la plus petite des $X_{i}$ précédentes pour i allant de 1 à n.\\
$X_{2}$ : la seconde plus petite des $X_{i}$ précédentes.\\
On a donc $X_{1}$ est le minimum des $X_{i}$ et $X_{n}$ le maximum des $X_{i}$.
On s'intéresse à l'évènement u<$X_{i}$<u+h\\
Cet évènement correspond à l'évènement que i-1 variable aléatoire ont une valeur inférieur à u, 1 variable aléatoire à une valeur dans [u, u+h] et n-i variables aléatoires ont une valeur supérieure à u+h.\\
La probabilité de cet évènement est une multinomiale où n essais sont distribués dans k=3 catégories avec les probabilités correspondantes.\\
P(u<$X_{i}$<u+h) = $\frac{n!}{(i-1)!(n-i)!} F_X(u)^{i-1}f_X(u)h[1-F_X(u+h)]^{n-i}$\\
où $F_X $: la fonction de répartition de X
et $f_X $: la fonction densité de X.\\
On a par ailleurs supposé que P(u<$X_{i}$<u+h)$\approx f_X(u)h$ quand h est petit.
Donc la densité de probabilité correspondante est :\\
$f_{X(i)}(x) = \frac{n!}{(i-1)!(n-i)!} F_X(u)^{i-1}f_X(u)h[1-F_X(u+h)]^{n-i}$\\
Si X est distribuée de façon uniforme sur (1-G) on a :
$f_X(x)=\frac{1}{G}$  $F_X(x)=\frac{x}{G}$\\
Dans ce cas : 
$f_{X(i)}(x) = \frac{n!}{(i-1)!(n-i)!} (\frac{x}{G})^{i-1} \frac{1}{G} [1-\frac{x}{G}]^{n-i}$ avec x $ \in $[0,L]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
\\Si on pose $ \frac{x}{G}$, $\alpha=i$, $\beta=n-i+1$, y$\in$[0,1]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \\ 
$f_{X(i)}(x)= \frac{(\alpha+\beta-1)!}{G(\alpha-1)!(\beta-1)!}y^{\alpha-1}(1-y)^{\beta-1}=\frac{1}{G}beta(i,n-i+1) $\\
On considère la densité de probabilité jointe pour $S_(i)$ et $S_{(i+1)}$\\
$f_{X(i)X(i+1)}(x,y) = \frac{n!}{(i-1)!(n-i-1)!} (\frac{x}{G})^{i-1} \frac{1}{G} \frac{1}{G}[1-\frac{y}{G}]^{n-i-1}$ y>x\\
L'évènement $D_i$=d est le même que $S_{(i+1)}=x+d sachant que S(i)=x$
P($D_i$=d)=P($S_{(i+1)}=x+d|S_i=x $)=$\frac{P(S_{(i+1)}=x+d,S_i=x}{P(S_i=x)} $\\
Donc $\frac{(n-i)(1-x-d)^{n-i-1}}{G(1-x)^{n-i}}=\frac{n-i}{G(1-x)}[\frac{1-x-d}{1-x}]^{n-i-1}$ x$\in$[0,1]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   
On sait que l'ADN est découpé aléatoirement (shot gun) ce qui est comparable à découper un bâton aléatoirement en N morceaux. 
On prend un "bâton" de taille 1 000 000 que l'on coupe en N morceaux aléatoirement. \\
Soit N une variable aléatoire qui représente le nombre de fragments obtenus.
Cette variable aléatoire dépend de la personne qui manipule. En effet, si la personne travaille soigneusement N devrait être petit comparée au N obtenus par une personne qui ne travaille pas soigneusement.\\

On considère dans un premier temps que N suit une loi de poisson de probabilité : 
$p_{H}(N=n) =\frac{\lambda^{n}e^{-\lambda}}{n!}$
avec $\lambda >0 $ et N entier naturel.

Soit $X_i$ avec i =1,2,... la taille des fragments obtenus 
$X_i$ sont indépendantes et identiquement distribuées selon une distribution bêta de paramètres $\alpha = 1$ et $\beta=n$.
$p_{H}(x) =n(1-x)^{n-1}$ avec $x\in[0,1]$\\
$p_{H}(x) = \sum_{i=0}^{+\infty}n(1-x)^{n-1}\frac{\lambda^{n}e^{-\lambda}}{n!}$\\
$p_{H}(x)= \lambda e^{-\lambda}\sum_{i=0}^{+\infty}\frac{(\lambda (1-x))^{n-1}}{(n-1)!}$ \\
$p_{H}(x)= \lambda e^{-\lambda}\sum_{i=1}^{+\infty}\frac{(\lambda (1-x))^{n}}{(n)!} + \frac{\lambda^{2}e^{-\lambda}}{1-x}$ \\
$p_{H}(x)= \lambda e^{-\lambda x} + \frac{\lambda^{2}e^{-\lambda}}{1-x}$ \\
C'est la densité de la loi composée bêta avec la loi de poisson de paramètre$\lambda$. \\
$p_{H}(x) = \sum_{n=0}^{+\infty}n(1-x)^{n-1}\frac{\lambda^{n}e^{-\lambda}}{n!} \\ p_{H}(x) = \sum_{n=1}^{+\infty}n(1-x)^{n-1}\frac{\lambda^{n}e^{-\lambda}}{n!} + 0 \\
p_{H}(x) = \lambda e^{-\lambda}\sum_{k=0}^{+\infty}\frac{((1-x)\lambda)^{k}}{(k)!} \\
p_{H}(x) = \lambda e^{-\lambda}e^{(1-x)\lambda} \\
p_{H}(x) = \lambda e^{-\lambda x}
$ \\
On trace cette densité et on obtient le graphique suivant : \\
\includegraphics[scale=0.5]{betapoiss.png}\\
On remarque que la moyenne de la loi poisson $\lambda$ se retrouve pour x = 0. 
\\On fait de même en composant la loi bêta avec la loi uniforme de paramètres : a, b \\
$p_{H}(x) = \int_{a}^{b}n(1-x)^{n-1}\frac{1}{b-a}dn$\\
On trouve : $ p_{H}(x)=\frac{e^{-ln(1-x)}}{b-a}(\frac{be^{bln(1-x)}-ae^{aln(1-x)}}{ln(1-x)}+ \frac{e^{aln(1-x)}-e^{bln(1-x)}}{(ln(1-x))^2})$\\

Pour la loi bêta-normale, $p_{H}(x) = \int_{0}^{+\infty}n(1-x)^{n-1}\frac{e^{\frac{-(n-\mu)^2}{2\sigma^2}}}{\sigma\sqrt{2\pi}}dn$
$p_{H}(x)=\frac{k1k2\sigma^2}{sqrt{2\pi}}(ln(1-x)+\frac{\mu}{\sigma^2})(1-x)^{\mu^2 - 1}e^{\frac{\sigmaln(1-x)}{sqrt(2}}(1-erf(\frac{-b}{2sqrt{a}})-\frac{k1\sigma}{(1-x)sqrt{2\pi}}$
\section{Conclusion - Perspectives} 
lander-watermann
\newpage
\listoffigures
\newpage
\newpage
\bibliographystyle{plain-fr}
\nocite{*}
\bibliography{rapport}
\end{document} 

















