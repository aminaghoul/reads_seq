\documentclass{book}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\begin{document}

Remerciements

Avant tout développement sur cette expérience professionnelle, il apparaît opportun de commencer ce rapport de stage par des remerciements, à ceux qui m’ont beaucoup appris au cours de ce stage, et même à ceux qui ont eu la gentillesse de faire de ce stage un moment très profitable.

Aussi, je remercie [•], mon maître de stage qui m’a formé et accompagné tout au long de cette expérience professionnelle avec beaucoup de patience et de pédagogie. Enfin, je remercie l’ensemble des employés de [•] pour les conseils qu’ils ont pu me prodiguer au cours de ces deux mois.


Le  sujet du stage concerne l'exploitation des données (lectures)
produites par les technologies de séquençage de 3e génération.

Contrairement aux précédentes générations qui fournissaient des lectures
de longueur constante et petite (au plus 400 bp), les technologies de 3e
génération produisent une distribution de longueurs avec une médiane à
environ 12 kbp et une queue de distribution qui va jusqu'à 60 kbp pour les
lectures les plus longues.

Dans un premier temps, j'aimerais vérifier l'idée que les distributions ainsi obtenues sont des distributions bêta (cas classique de la distribution
des longueurs des morceaux d'un bâton qui a été découpé en N segments
aléatoirement). Dans le cas du séquençage, N est sans doute aussi une
variable aléatoire avec une distribution qui reste à déterminer.
Nous avons dans un premier temps vérifier que les tailles de lectures suivent une loi de distribution bêta.

\includegraphics[scale=0.5]{taille_reads_minion.png} 

C'est le graphique de l'histogramme des tailles de reads.
On sait que cette distribution de tailles suit une loi de bêta de paramètres 1 et n.
On peut le montrer théoriquement. \\
On s'intéresse au positionnement de lecture $S_{i}$ sur un génome de taille G. $S_{i}$ : position de départ de la $i_{ème}$ lecture sur le génome.\\
Les lectures sont générées aléatoirement et uniformément le long du génome.
Soit $D_{i}$= $S_{i+1}$-$S_{i}$ la distance entre 2 positions de départ consécutives.
On s'intéresse aux statistiques d'ordre.\\
Soit X une variable aléatoire continue et $X_{1}$, $X_{2}$, ... $X_{n}$ des variables aléatoires indépendantes et identiquement distribuées selon la distribution de X.
On définit $X_{1}$ comme la plus petite des $X_{i}$ précédentes pour i allant de 1 à n.\\
$X_{2}$ : la seconde plus petite des $X_{i}$ précédentes.\\
On a donc $X_{1}$ est le minimum des $X_{i}$ et $X_{n}$ le maximum des $X_{i}$.
On s'intéresse à l'évènement u<$X_{i}$<u+h\\
Cet évènement correspond à l'évènement que i-1 variable aléatoire ont une valeur inférieur à u, 1 variable aléatoire à une valeur dans [u, u+h] et n-i variables aléatoires ont une valeur supérieure à u+h.\\
La probabilité de cet évènement est une multinomiale où n essais sont distribués dans k=3 catégories avec les probabilités correspondantes.\\
P(u<$X_{i}$<u+h) = $\frac{n!}{(i-1)!(n-i)!} F_X(u)^{i-1}f_X(u)h[1-F_X(u+h)]^{n-i}$\\
où $F_X $: la fonction de répartition de X
et $f_X $: la fonction densité de X.\\
On a par ailleurs supposé que P(u<$X_{i}$<u+h)$\approx f_X(u)h$ quand h est petit.
Donc la densité de probabilité correspondante est :\\
$f_{X(i)}(x) = \frac{n!}{(i-1)!(n-i)!} F_X(u)^{i-1}f_X(u)h[1-F_X(u+h)]^{n-i}$\\
Si X est distribuée de façon uniforme sur (1-G) on a :
$f_X(x)=\frac{1}{G}$  $F_X(x)=\frac{x}{G}$\\
Dans ce cas : 
$f_{X(i)}(x) = \frac{n!}{(i-1)!(n-i)!} (\frac{x}{G})^{i-1} \frac{1}{G} [1-\frac{x}{G}]^{n-i}$ avec x $ \in $[0,L]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       
\\Si on pose $ \frac{x}{G}$, $\alpha=i$, $\beta=n-i+1$, y$\in$[0,1]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \\ 
$f_{X(i)}(x)= \frac{(\alpha+\beta-1)!}{G(\alpha-1)!(\beta-1)!}y^{\alpha-1}(1-y)^{\beta-1}=\frac{1}{G}beta(i,n-i+1) $\\
On considère la densité de probabilité jointe pour $S_(i)$ et $S_{(i+1)}$\\
$f_{X(i)X(i+1)}(x,y) = \frac{n!}{(i-1)!(n-i-1)!} (\frac{x}{G})^{i-1} \frac{1}{G} \frac{1}{G}[1-\frac{y}{G}]^{n-i-1}$ y>x\\
L'évènement $D_i$=d est le même que $S_{(i+1)}=x+d sachant que S(i)=x$
P($D_i$=d)=P($S_{(i+1)}=x+d|S_i=x $)=$\frac{P(S_{(i+1)}=x+d,S_i=x}{P(S_i=x)} $\\
Donc $\frac{(n-i)(1-x-d)^{n-i-1}}{G(1-x)^{n-i}}=\frac{n-i}{G(1-x)}[\frac{1-x-d}{1-x}]^{n-i-1}$ x$\in$[0,1]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   

On sait que l'ADN est découpé aléatoirement (shot gun) ce qui est comparable à découper un bâton aléatoirement en N morceaux. 
On prend un "bâton" de taille 1 000 000 que l'on coupe en 60 000 morceaux aléatoirement. 
On fit cet histogramme avec distribution bêta(1,N) où N est le nombre de lectures.Nous obtenons l'histogramme suivants : \\
\includegraphics[scale=0.5]{hist.png}

Pour vérifier que cette distribution suit une loi bêta de paramètres (1, 60 000), nous allons normaliser les tailles obtenues en les divisant par 1 000 000.\\
\includegraphics[scale=0.5]{histbeta.png}\\
La courbe rouge correspond à la densité de la loi bêta (1,60 000).\\
On a estimer les paramètres de la loi bêta en utilisant la méthode du maximum de vraisemblance. En effet, nous avons minimiser la log vraisemblance négative et nous avons trouvé comme paramètres : 

alpha = 1.1752289930435111 et bêta = 70512.1437318023
Nous avons également estimé ces paramètres en utilisant la méthode des moments et on trouve : 
alpha = 1.0575435001952862 et bêta = 63451.552468207636

\includegraphics[scale=0.5]{histbetamv.png}\\
Pour déterminer la variable aléatoire N on a tout d'abord testé plusieurs lois : loi binomiale, uniforme, poisson. \\
En effet, la valeur du nombre de morceaux est entière on peut alors supposer que la variable aléatoire N est discrète.
Avec N=65000, correspondant à la moyenne de chacune de ces lois.
\\
\includegraphics[scale=0.5]{binomiale.png}
\includegraphics[scale=0.5]{uniforme.png}\\
\includegraphics[scale=0.5]{poisson.png}

On peut supposer que N suit une loi de poisson car ...
On calcule la densité de la loi composée H de la loi bêta F et uniforme G de paramètres nmin, nmax.

$p_{H}(x) = \int_{0}^{b} p_{F}(x|\theta) p_{G}(\theta)d\theta$

$p_{H}(x) = \frac{e^{-ln(1-x)}}{nmax-nmin}(\frac{nmaxe^{nmaxln(1-x)}-nmine^{nminln(1-x)}}{ln(1-x)}+\frac{e^{nminln(1-x)}-e^{nmaxln(1-x)}}{(ln(1-x))^2})$



On trace cette densité en prenant b = 60 000*2.
En effet, on suppose que 60 000 est égal à l'espérance de la loi uniforme de paramètres 0,b.\\
\includegraphics[scale=0.5]{beta_unif.png}\\
On remarque que cette densité ressemble à la densité de la loi bêta de paramètres 1, 60 000. \\
On calcule la densité de la loi composée H de la loi bêta F et de poisson G.


$p_{H}(x) = \int_{0}^{+\infty} p_{F}(x|\theta) p_{G}(\theta)d\theta$

$p_{H}(x) = \sum_{i=0}^{+\infty}n(1-x)^{n-1}\frac{\lambda^{n}e^{-\lambda}}{n!}$

Soit N une variable aléatoire discrète qui représente le nombre de fragments obtenus.
On considère dans un premier temps que N suit une loi de poisson de probabilité : 
$p_{H}(N=n) =\frac{\lambda^{n}e^{-\lambda}}{n!}$
avec $\lambda >0 $ et N entier naturel.

Soit $X_i$ avec i =1,2,... la taille des fragments obtenus 
$X_i$ sont indépendantes et identiquement distribuées selon une distribution bêta de paramètres $\alpha = 1$ et $\beta=n$.
$p_{H}(x) =n(1-x)^{n-1}$ avec $x\in[0,1]$\\
$p_{H}(x) = \sum_{i=0}^{+\infty}n(1-x)^{n-1}\frac{\lambda^{n}e^{-\lambda}}{n!}$\\
$p_{H}(x)= \lambda e^{-\lambda}\sum_{i=0}^{+\infty}\frac{(\lambda (1-x))^{n-1}}{(n-1)!}$ \\
$p_{H}(x)= \lambda e^{-\lambda}\sum_{i=1}^{+\infty}\frac{(\lambda (1-x))^{n}}{(n)!} + \frac{\lambda^{2}e^{-\lambda}}{1-x}$ \\
$p_{H}(x)= \lambda e^{-\lambda x} + \frac{\lambda^{2}e^{-\lambda}}{1-x}$ \\
C'est la densité de la loi composée bêta avec la loi de poisson de paramètre$\lambda$. \\
$p_{H}(x) = \sum_{n=0}^{+\infty}n(1-x)^{n-1}\frac{\lambda^{n}e^{-\lambda}}{n!} \\ p_{H}(x) = \sum_{n=1}^{+\infty}n(1-x)^{n-1}\frac{\lambda^{n}e^{-\lambda}}{n!} + 0 \\
p_{H}(x) = \lambda e^{-\lambda}\sum_{k=0}^{+\infty}\frac{((1-x)\lambda)^{k}}{(k)!} \\
p_{H}(x) = \lambda e^{-\lambda}e^{(1-x)\lambda} \\
p_{H}(x) = \lambda e^{-\lambda x}
$
On trace cette densité et on obtient le graphique suivant : \\
\includegraphics[scale=0.5]{betapois.png}\\

Le pacbio : enlève par exemple longueurs <8kpb. Machine pas capable de traiter les morceaux en entiers elle doit les tronquer.

MINION biais tirer les plus petits.

J'insère le premier \cite{ref}, le second \cite{ref2}, le troisième \cite{ref3}, le quatrième \cite{ref4}, le cinquième \cite{ref5} et le sixième \cite{ref6}.

\bibliographystyle{} % Le style est mis entre accolades.
\bibliography{biblio} % mon fichier de base de données s'appelle bibli.bib
\bibliographystyle{plain}

\end{document}